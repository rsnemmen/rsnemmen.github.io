<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://rsnemmen.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rsnemmen.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-01-25T22:32:38+00:00</updated><id>https://rsnemmen.github.io/feed.xml</id><title type="html">Rodrigo Nemmen’s website</title><subtitle>Rodrigo Nemmen&apos;s Data Science and Machine Learning Portfolio. </subtitle><entry><title type="html">The state of agentic coding</title><link href="https://rsnemmen.github.io/blog/2026/the-state-of-agentic-coding/" rel="alternate" type="text/html" title="The state of agentic coding"/><published>2026-01-25T22:19:00+00:00</published><updated>2026-01-25T22:19:00+00:00</updated><id>https://rsnemmen.github.io/blog/2026/the-state-of-agentic-coding</id><content type="html" xml:base="https://rsnemmen.github.io/blog/2026/the-state-of-agentic-coding/"><![CDATA[<p>With the <a href="https://www.nytimes.com/2026/01/23/technology/claude-code.html">explosion</a> of <a href="https://code.claude.com/docs/en/overview">Claude Code</a>, developers are struggling with handle the credit limits. I have seen plenty of Reddit posts complaining about the limitations imposed by the Claude Max plan, even though it costs a whopping $200!</p> <p>I access Anthropic’s models using the <a href="https://poe.com/login">Poe API service</a>, which also gives me access to models by the other major players in the field. In my experience with CC so far, I can easily burn a few percent of the monthly credits in a few minutes of use in a complex codebase—even if you stick with Sonnet, Anthropic’s mid-tier clippy. I can totally see my monthly API credit (about $30) vanishing within one or two days of intense CC sessions in a complex scientific codebase.</p> <p>I am not spending a couple hundred dollars on clippies, so I have been exploring alternative ways of doing agentic coding and alternative providers. In my explorations, I found <a href="https://opencode.ai/">opencode</a>: another fantastic terminal-based agentic coding interface which gives you access to other models in addition to Claude. <sup class="footnote-ref" id="fnref-1"><a href="#fn-1">1</a></sup> More importantly, it gives me access to a locally-hosted LLM (more about that in another post).</p> <p>In order to see what else is out there in terms of agentic-coding LLMs and rank their cost-benefit, I crawled the major relevant benchmarks out there. I computed the average ranking of major models, including how much they cost. I went through the following benchmarks in no particular order:</p> <ul> <li><a href="https://gorilla.cs.berkeley.edu/leaderboard.html#leaderboard">Berkeley Function-Calling Leaderboard</a></li> <li><a href="https://www.swebench.com">SWE-bench</a></li> <li><a href="https://livebench.ai/#/">LiveBench</a></li> <li><a href="https://lmarena.ai/leaderboard">LMArena</a> (with the usual disclaimer that this is based on benchmarks weighted by popular votes, so it is really a popular preference ranking; still useful though)</li> <li><a href="https://scale.com/leaderboard/swe_bench_pro_public">Scale’s SWE-Bench Pro (Public Dataset)</a></li> </ul> <p>Here is the ranking:</p> <table> <thead> <tr> <th>Ranking</th> <th>Model Name</th> <th>Average Score</th> <th>Credit Cost (per 1k)</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>opus</td> <td>1.00</td> <td>850</td> </tr> <tr> <td>2</td> <td>gemini</td> <td>2.75</td> <td>370</td> </tr> <tr> <td>3</td> <td>gpt</td> <td>5.25</td> <td>470</td> </tr> <tr> <td>4</td> <td>gpt-pro</td> <td>5.50</td> <td>5600</td> </tr> <tr> <td>5</td> <td>sonnet</td> <td>6.25</td> <td>500</td> </tr> <tr> <td>6</td> <td>minimax</td> <td>6.67</td> <td>50</td> </tr> <tr> <td>7</td> <td>gpt-codex</td> <td>10.00</td> <td>340</td> </tr> <tr> <td>8</td> <td>gemini-flash</td> <td>12.00</td> <td>100</td> </tr> <tr> <td>9</td> <td>deepseek-32</td> <td>13.67</td> <td>23</td> </tr> <tr> <td>10</td> <td>kimi</td> <td>14.00</td> <td>225</td> </tr> <tr> <td>11</td> <td>glm</td> <td>14.33</td> <td>94</td> </tr> <tr> <td>12</td> <td>haiku</td> <td>15.00</td> <td>170</td> </tr> <tr> <td>13</td> <td>devstral-small</td> <td>24.50</td> <td>1</td> </tr> <tr> <td>14</td> <td>gpt-instant</td> <td>26.67</td> <td>470</td> </tr> <tr> <td>15</td> <td>qwen3-80b</td> <td>28.33</td> <td>300</td> </tr> <tr> <td>16</td> <td>grok-fast</td> <td>31.00</td> <td>20</td> </tr> <tr> <td>17</td> <td>grok</td> <td>31.50</td> <td>600</td> </tr> <tr> <td>18</td> <td>qwen3-coder-30b</td> <td>32.67</td> <td>50</td> </tr> <tr> <td>19</td> <td>devstral2</td> <td>72.00*</td> <td>N/A</td> </tr> <tr> <td>20</td> <td>mistral</td> <td>79.00*</td> <td>400</td> </tr> <tr> <td>21</td> <td>llama-maverick</td> <td>80.00*</td> <td>55</td> </tr> <tr> <td>22</td> <td>qwen3-235b</td> <td>88.00*</td> <td>N/A</td> </tr> </tbody> </table> <p><em>Table showing the LLM ranking for agentic coding. When a model does not include the version, it refers to the latest version available (i.e. <code>gemini</code> means Gemini 3 Pro High, <code>gpt</code> means GPT 5.2 High). Scores with an asterisk include a +50 penalty for incomplete information (only 1 ranking source). Credit cost is the relative cost per 1000 tokens of input and output.</em></p> <p>Here is a plot showing the model's score as a function of how much it cost per 1k tokens.</p> <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/residuals/19pm.webp" alt="Screenshot 2026-01-25 at 2"/></p> <p>It comes as no surprise that Opus 4.5, Gemini 3 Pro and GPT 5.2 are among the top 3. But notice how open models are getting quite competitive: Minimax M2.1, DeepSeek v3.2 and Kimi K2—all open models which anyone can download—are among the top 10. Also notice how Minimax offers coding performance as good as Sonnet 4.5 but costing 10 times less.</p> <p>My take from this? Whenever possible I will stick with opencode and Minimax for day-to-day coding tasks. When I need the big guns, I will use CC/Sonnet/Opus.</p> <hr/> <section class="footnotes"> <ol> <li id="fn-1"><p>Recently Anthropic devs enabled CC to talk to other clippies besides Claude. My experience so far with CC 2.1.15 is that it does not work very well and CC crashes as soon as you try to make it talk to a locally-hosted Ollama model.<a href="#fnref-1" class="footnote">&#8617;</a></p></li> </ol> </section>]]></content><author><name></name></author></entry><entry><title type="html">Nature News &amp;amp; Views article</title><link href="https://rsnemmen.github.io/blog/2026/nature-news-views-article/" rel="alternate" type="text/html" title="Nature News &amp;amp; Views article"/><published>2026-01-14T16:55:44+00:00</published><updated>2026-01-14T16:55:44+00:00</updated><id>https://rsnemmen.github.io/blog/2026/nature-news--views-article</id><content type="html" xml:base="https://rsnemmen.github.io/blog/2026/nature-news-views-article/"><![CDATA[<p>Nature asked me to write a <a href="https://rdcu.be/eY4PS">News &amp; Views article</a> on a <a href="https://www.nature.com/articles/s41586-025-09900-4">recent hot result</a> on little red dots. N&amp;V articles explain the results of new research paper in a way that is accessible to a broad community of scientists outside the specific field, while giving the author’s opinion on the work. LRDs are the hottest thing in astronomy right now, and nobody really knows their nature (no pun intended). As you will learn in <a href="https://rdcu.be/eY4PS">my N&amp;V piece</a>, the astronomical community is converging on a “hey, actually they are growing massive black holes” kind of model.</p> <p>I hope you enjoy my article.</p> <h2 id="acknowledgements">Acknowledgements</h2> <p>It can be tricky writing to a broad community of scientists. I would like to thank the following colleagues who gave me feedback on the first draft of the N&amp;V piece: Rafael de Souza (fast responder!), Paula Coelho, Matt Luzum, Gastão Lima Neto, Nina Hirata, Thaisa Storchi Bergmann, Rafael Ribeiro and Raniere de Menezes.</p>]]></content><author><name></name></author></entry><entry><title type="html">From horizon scales to cocoons: My favorite black hole papers of 2025</title><link href="https://rsnemmen.github.io/blog/2026/from-horizon-scales-to-cocoons-my-favorite-black-hole-papers-of-2025/" rel="alternate" type="text/html" title="From horizon scales to cocoons: My favorite black hole papers of 2025"/><published>2026-01-08T22:19:00+00:00</published><updated>2026-01-08T22:19:00+00:00</updated><id>https://rsnemmen.github.io/blog/2026/from-horizon-scales-to-cocoons-my-favorite-black-hole-papers-of-2025</id><content type="html" xml:base="https://rsnemmen.github.io/blog/2026/from-horizon-scales-to-cocoons-my-favorite-black-hole-papers-of-2025/"><![CDATA[<p>New year, new science. Time to think about my favorite papers of 2025. This is of course a hugely biased list, convolved with my personal scientific preferences. This list will be focused on the topics of black hole astrophysics.</p> <p>&lt;h2 id=phenomenology-agns-little-red-dots&gt;Phenomenology: AGNs, little red dots&lt;/h2&gt;&lt;p&gt;Not a terribly exciting year on the observational front for AGNs and black hole binaries. If you discount little red dots, that is.&lt;/p&gt;</p> <p>There were the <a href="https://www.aanda.org/articles/aa/full_html/2025/12/aa55855-25/aa55855-25.html">polarization flips observed in M87* on horizon scales</a>. Really hard work, and in my opinion polarization offers the biggest science lessons from EHT. No surprises in the polarization properties mapped. All variability is consistent with accretion physics expectations (good!).</p> <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/residuals/resampled_triptych_eht_labeled_1.webp" alt="resampled_triptych_EHT_labeled_1"/> <em>Prettified polarization maps on horizon scales (by prettified I mean line integral convolution images, looks good!). From <a href="https://www.aanda.org/articles/aa/full_html/2025/12/aa55855-25/aa55855-25.html">EHTC (2025)</a>.</em></p> <p>For me, the biggest puzzle in polarization studies is the following. Sgr A* and M87* have basically the same polarization properties. The same GRMHD models explain the observations: a MAD around a rapidly rotating black hole with <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>a</mi><mo>&#x0002A;</mo></msub><mo>&#x02248;</mo><mn>0.9</mn></mrow></math>. <em>So why the heck does M87 produce huge jets while Sgr A shows none of them?</em>. If you feed such a Kerr black hole with lots of magnetic fields, you should get strong jets. What is special about Sgr A* then? And no, I do not believe in the evidence so far for jets from Sgr A*.</p> <p>The hottest thing in the observational front right now—and honestly in all fields of astronomy—is the <em>little red dot</em> phenomenon. This is a transformational field where we know very little about what is behind those sources. Comparable to when quasars were discovered, or gamma-ray bursts. It is breath-taking and hard to catch up with so many papers being posted (about 200 since LRDs were discovered two years ago).</p> <p>The top-2 results on LRDs this year were:</p> <p>(1) <a href="https://arxiv.org/abs/2503.16595">High S/N JWST spectra of LRDs are better explained by exponential line profiles</a>. This has huge implications because the line broadening we are seeing would be mostly explained by Thomson scattering in an optically thick, highly-ionized medium, not virial motion around a central mass. This is important evidence that LRDs are growing massive black holes enshrouded in a cocoon—which some authors are calling a <a href="https://arxiv.org/abs/2503.16596">“black hole star”</a> (I hate that term, confusing on so many levels)—and they are not overmassive with respect to their galaxies as many authors think.</p> <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/residuals/06pm.webp" alt="Screenshot 2026-01-08 at 3"/> <em>Exponential fit to one of the high S/N little red dot line profiles compiled performed by <a href="https://arxiv.org/abs/2503.16595">Rusakov+2025</a>. In my opinion, the money plot of this paper is in the supplementary material—Extended Figure 7, which shows how statistically superior the exponential fits are, compared to Gaussians.</em></p> <p>(2) <a href="https://arxiv.org/abs/2412.04224v2">LRDs don’t produce radio emission</a>. If they host accreting black holes, that is weird. We should see at least some of them with some radio emission. But then, if (1) above is correct, it would explain why we should not expect so much radio from these guys.</p> <p>I think we can pretty much say that LRDs are not just galaxies. So we can move on and focus on the black hole explanation.</p> <p>&lt;h2 id=theory-tilted-disks-kinetic-multizone-simulations&gt;Theory: tilted disks, kinetic, multizone simulations&lt;/h2&gt;&lt;p&gt;There has been amazing progress in the theoretical front, particularly in multiscale GRMHD and kinetic simulations. Part of that is due to new algorithms being implemented, particularly in the kinetic case. Who would say that we would be talking about GR-kinetic simulations in the 2020s? But most of the progress is happening, I think, because Moore’s law is allowing us to solve equations with dense meshes that were unthinkable a couple of years ago. Yay, NVIDIA.&lt;/p&gt;</p> <p>There has been important progress in <a href="https://iopscience.iop.org/article/10.3847/1538-4357/adce79">simulating spark gaps in Kerr black hole magnetospheres</a>. We need much more of this if we want to understand how plasma is maintained near event horizons, and how are jets produced (Blandford-Znajek is only part of the story). This is a regime where GRMHD can only take you so far.</p> <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/residuals/25pm.webp" alt="Screenshot 2026-01-08 at 3"/> <em>Snapshots showing cross-sectional cuts of several variables from a 2D GR-kinetic simulation. Dashed line is the ergosphere. From <a href="https://iopscience.iop.org/article/10.3847/1538-4357/adce79">Yuan+2025</a>.</em></p> <p>We have the <a href="https://arxiv.org/abs/2311.00432">impressive work of the <code>H-AMR</code> folks</a> systematically exploring disk tilts and seeing what comes out of it.</p> <p>And finally, we have the <a href="https://arxiv.org/abs/2507.17818v1">multizone GRMHD simulations bridging the gap from horizon scales up to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>&#x0007E;</mi><mn>100</mn></mrow></math> Bondi radii</a>! Incredible work based on <a href="https://iopscience.iop.org/article/10.1088/0004-637X/761/2/130">a simple and powerful insight on how to connect boundary conditions</a> by Feng Yuan and collaborators.</p> <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/residuals/23pm.webp" alt="Screenshot 2026-01-08 at 3"/> <em>Multizone GRMHD simulation: Feeding and feedback from jets and winds out to <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mn>10</mn><mn>7</mn></msup><msub><mi>r</mi><mi>g</mi></msub></mrow></math> (kpc-scale for <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mn>10</mn><mn>8</mn></msup><msub><mi>M</mi><mo>&#x02299;</mo></msub></mrow></math>). From <a href="https://arxiv.org/abs/2507.17818v1">Cho+2025</a>.</em></p> <p>Excited to see what 2026 will bring.</p> <p>--</p> <h2 id="changelog">Changelog</h2> <ul> <li>v1, 1-8-2025, 1pm: published post</li> <li>v2, 1-8-2025, 4pm: added figures</li> </ul>]]></content><author><name></name></author></entry><entry><title type="html">AGN jets review talk at Zihuatanejo</title><link href="https://rsnemmen.github.io/blog/2025/agn-jets-review-talk-at-zihuatanejo/" rel="alternate" type="text/html" title="AGN jets review talk at Zihuatanejo"/><published>2025-12-17T04:12:52+00:00</published><updated>2025-12-17T04:12:52+00:00</updated><id>https://rsnemmen.github.io/blog/2025/agn-jets-review-talk-at-zihuatanejo</id><content type="html" xml:base="https://rsnemmen.github.io/blog/2025/agn-jets-review-talk-at-zihuatanejo/"><![CDATA[<p>I was invited to give a review talk about relativistic jets from AGN in the <a href="https://zihuagn.irya.unam.mx">”AGN redemption" conference</a>. The venue was at beautiful, humid Zihuatanejo. I haven't been in such a excruciatingly hot place since I lived in Porto Alegre, or when I visited Rio during summer. So if you are wondering if Zihuatanejo is warm at the end of October: yes sir! Very much so.</p> <p>Anyway, the organizers asked me to give a comprehensive overview (30 minutes) of "jet formation and evolution". The theme of the conference was the <a href="https://www.imdb.com/title/tt0111161/?ref_=nv_sr_srsg_0_tt_8_nm_0_in_0_q_shawshank">Shawshank Redemption</a> movie, because this is the place where the movie ends (if you haven't watched the movie, go stream it). So the organizers made a big deal about it. They asked the presenters to mention their favorite movie at the end of each talk. Most of them did, but I chose not to because I did not have 1 minute to spare in my review talk (reviewing the entire field of AGN jets in 30 minutes is no easy task, it turns out).</p> <p>I decided to pick about ten papers in the field that caught my attention in the last 2-3 years, and focused on those papers and why they are relevant. And I strictly concentrated on formation, dynamics/kinematics and the status of the radio-loud/radio-quiet division. The slides are <a href="https://doi.org/10.6084/m9.figshare.30899891">available here</a>. For future reference, the talk was given on October 31st 2025.</p> <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/nemmen/03pm.webp" alt="Screenshot 2025-12-16 at 8"/></p> <p>By the way, I should point out a correction to the slide 27 about the second M87* ring: even though I wrote in the slide that it was observed by EHT, it was actually seen by ALMA+GLT+GMVA. My bad.</p>]]></content><author><name></name></author></entry><entry><title type="html">Fuzzy file operations with fuzzycp</title><link href="https://rsnemmen.github.io/blog/2025/fuzzy_file_operations/" rel="alternate" type="text/html" title="Fuzzy file operations with fuzzycp"/><published>2025-07-02T23:00:00+00:00</published><updated>2025-07-02T23:00:00+00:00</updated><id>https://rsnemmen.github.io/blog/2025/fuzzy_file_operations</id><content type="html" xml:base="https://rsnemmen.github.io/blog/2025/fuzzy_file_operations/"><![CDATA[<p>I just created a new program that performs file operations with fuzzy filename matching: <a href="https://github.com/rsnemmen/fuzzy_cp">fuzzycp</a>. In order to understand what that means, here is a concrete example.</p> <p>Suppose you have a file <code class="language-plaintext highlighter-rouge">names.txt</code> containing a list of names you want to match against. Let’s say the content of this file is:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. The Legend of Zelda: Ocarina of Time
2. Super Mario 64
3. Mario Kart 64
4. GoldenEye 007
5. Super Smash Bros.
</code></pre></div></div> <p>This is a random example—the top five games released for the Nintendo 64 console. Now, you have a directory with thousands of files, and you want to copy to another directory only the files that are the best-match to the names in the above list. Here are some examples of files in that directory:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'Spider-Man (U) [!].v64'
'StarCraft 64 (U) [!].v64'
'Starfox 64 1.1 (U).v64'  
'Starshot - Space Circus Fever (U) [!].z64'
'Star Wars - Rogue Squadron (U) [!].v64'
'Star Wars - Shadows of the Empire (U) (V1.2) [!].v64'
'Star Wars Episode I - Battle for Naboo (U) [!].v64'
'Star Wars Episode I - Racer (U) [!].v64'
'Stunt Racer 64 (U) [!].z64'
'Super Bowling 64 (U) [!].z64'
'Supercross 2000 (U) [!].z64'
'Superman (U) (M3) [!].z64'
'Super Mario 64 (U) [!].v64'
</code></pre></div></div> <p>For the sake of our example, the content of these files is meaningless (let’s say they have the metadata for those games). Notice that there will be no exact match between the names in <code class="language-plaintext highlighter-rouge">names.txt</code> and the actual filenames. They could have different casing, missing text, extra letters etc. This is where the power of fuzzy matching shines: you don’t need an exact match.</p> <h2 id="how-fuzzycp-solves-this-problem">How fuzzycp solves this problem</h2> <p>Normally people would do this sort of thing by manually selecting file by file and copying them. Not anymore. Here is how you solve this using <code class="language-plaintext highlighter-rouge">fuzzycp</code>, doing in a few seconds what would take potentially hours:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fuzzycp names.txt -c dest/directory
</code></pre></div></div> <p>After asking for the user’s confirmation and showing a list of the bestCopy only the best-matching files to directory <code class="language-plaintext highlighter-rouge">dest/directory</code>:</p> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fuzzycp-480.webp 480w,/assets/img/fuzzycp-800.webp 800w,/assets/img/fuzzycp-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/fuzzycp.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Internally, fuzzycp compares the names using the <code class="language-plaintext highlighter-rouge">QRatio</code>(Quick Ratio) scorer, which uses a simple Levenshtein-based percentage after basic lowercase/whitespace cleaning. This is the fastest scorer in RapidFuzz, useful for quick filters or typo-level comparisons. More sophisticated scorer can easily be implemented.</p> <h2 id="get-fuzzycp-today">Get fuzzycp today!</h2> <p>fuzzycp is <a href="https://github.com/rsnemmen/fuzzy_cp">available on Github</a>.</p>]]></content><author><name></name></author><category term="software"/><category term="projects"/><category term="software"/><summary type="html"><![CDATA[I just created a new program that performs file operations with fuzzy filename matching: fuzzycp. In order to understand what that means, here is a concrete example.]]></summary></entry><entry><title type="html">Model deployment with FastAPI and Docker</title><link href="https://rsnemmen.github.io/blog/2025/deploy/" rel="alternate" type="text/html" title="Model deployment with FastAPI and Docker"/><published>2025-05-01T22:00:00+00:00</published><updated>2025-05-01T22:00:00+00:00</updated><id>https://rsnemmen.github.io/blog/2025/deploy</id><content type="html" xml:base="https://rsnemmen.github.io/blog/2025/deploy/"><![CDATA[<p>The ability to operationalize a machine-learning model is just as important as the model itself. In <a href="https://rsnemmen.github.io/projects/2_deploy/">this project</a> I demonstrate how a trained XGBoost classifier is (1) served via an API with FastAPI and (2) containerized with Docker and (3) deployed to Google Cloud Platform (Cloud Run).</p>]]></content><author><name></name></author><category term="data-science"/><category term="data-science"/><category term="projects"/><summary type="html"><![CDATA[The ability to operationalize a machine-learning model is just as important as the model itself. In this project I demonstrate how a trained XGBoost classifier is (1) served via an API with FastAPI and (2) containerized with Docker and (3) deployed to Google Cloud Platform (Cloud Run).]]></summary></entry></feed>